{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport torch.optim as optim\nfrom torch import nn\n\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-09-14T19:15:28.996872Z","iopub.execute_input":"2023-09-14T19:15:28.997610Z","iopub.status.idle":"2023-09-14T19:15:29.005777Z","shell.execute_reply.started":"2023-09-14T19:15:28.997570Z","shell.execute_reply":"2023-09-14T19:15:29.004807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    SEED = 42\n    IMAGE_SIZE = [256, 256]\n    BATCH_SIZE = 16\n    EPOCHS = 10\n    TARGET_COLS  = [\n        \"bowel_injury\", \"extravasation_injury\",\n        \"kidney_healthy\", \"kidney_low\", \"kidney_high\",\n        \"liver_healthy\", \"liver_low\", \"liver_high\",\n        \"spleen_healthy\", \"spleen_low\", \"spleen_high\",\n    ]\n\nconfig = Config()\nlen(Config.TARGET_COLS)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T19:15:29.008058Z","iopub.execute_input":"2023-09-14T19:15:29.009483Z","iopub.status.idle":"2023-09-14T19:15:29.019899Z","shell.execute_reply.started":"2023-09-14T19:15:29.009174Z","shell.execute_reply":"2023-09-14T19:15:29.018993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(Config.SEED)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T19:15:29.021018Z","iopub.execute_input":"2023-09-14T19:15:29.021519Z","iopub.status.idle":"2023-09-14T19:15:29.031497Z","shell.execute_reply.started":"2023-09-14T19:15:29.021485Z","shell.execute_reply":"2023-09-14T19:15:29.030287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"BASE_PATH = f\"/kaggle/input/rsna-atd-512x512-png-v2-dataset\"","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-14T19:15:29.034060Z","iopub.execute_input":"2023-09-14T19:15:29.035038Z","iopub.status.idle":"2023-09-14T19:15:29.041447Z","shell.execute_reply.started":"2023-09-14T19:15:29.034997Z","shell.execute_reply":"2023-09-14T19:15:29.040359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train\ndataframe = pd.read_csv(f\"{BASE_PATH}/train.csv\")\ndataframe[\"image_path\"] = f\"{BASE_PATH}/train_images\"\\\n                    + \"/\" + dataframe.patient_id.astype(str)\\\n                    + \"/\" + dataframe.series_id.astype(str)\\\n                    + \"/\" + dataframe.instance_number.astype(str) +\".png\"\ndataframe = dataframe.drop_duplicates()\n\ndataframe.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T19:15:29.042985Z","iopub.execute_input":"2023-09-14T19:15:29.043380Z","iopub.status.idle":"2023-09-14T19:15:29.161409Z","shell.execute_reply.started":"2023-09-14T19:15:29.043347Z","shell.execute_reply":"2023-09-14T19:15:29.160249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to handle the split for each group\ndef split_group(group, test_size=0.2):\n    if len(group) == 1:\n        return (group, pd.DataFrame()) if np.random.rand() < test_size else (pd.DataFrame(), group)\n    else:\n        return train_test_split(group, test_size=test_size, random_state=42)\n\n# Initialize the train and validation datasets\ntrain_data = pd.DataFrame()\nval_data = pd.DataFrame()\n\n# Iterate through the groups and split them, handling single-sample groups\nfor _, group in dataframe.groupby(config.TARGET_COLS):\n    train_group, val_group = split_group(group)\n    train_data = pd.concat([train_data, train_group], ignore_index=True)\n    val_data = pd.concat([val_data, val_group], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T19:15:29.164717Z","iopub.execute_input":"2023-09-14T19:15:29.165031Z","iopub.status.idle":"2023-09-14T19:15:29.270166Z","shell.execute_reply.started":"2023-09-14T19:15:29.164996Z","shell.execute_reply":"2023-09-14T19:15:29.269138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.shape, val_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-14T19:15:29.271953Z","iopub.execute_input":"2023-09-14T19:15:29.272702Z","iopub.status.idle":"2023-09-14T19:15:29.280228Z","shell.execute_reply.started":"2023-09-14T19:15:29.272668Z","shell.execute_reply":"2023-09-14T19:15:29.279050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# torch dataloader with augmentation","metadata":{}},{"cell_type":"code","source":"paths  = train_data.image_path.tolist()\nlabels = train_data[config.TARGET_COLS].values\n\nclass CustomDataset(Dataset):\n    def __init__(self, paths, labels, transform=None):\n        self.paths = paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n        image = Image.open(self.paths[idx]).convert('RGB')\n        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\n# Define any image transformations you want to apply, here we also add augmentation. \ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.RandomResizedCrop(256),   # Random crop and resize\n    transforms.RandomHorizontalFlip(),    # Random horizontal flip\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color jitter\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])","metadata":{"execution":{"iopub.status.busy":"2023-09-14T19:15:29.281688Z","iopub.execute_input":"2023-09-14T19:15:29.282157Z","iopub.status.idle":"2023-09-14T19:15:29.296188Z","shell.execute_reply.started":"2023-09-14T19:15:29.282118Z","shell.execute_reply":"2023-09-14T19:15:29.295062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Converting Dataframe to dataloader","metadata":{}},{"cell_type":"code","source":"# get image_paths and labels\nprint(\"[INFO] Building the dataset...\")\n\ntrain_paths  = train_data.image_path.tolist()\ntrain_labels = train_data[config.TARGET_COLS].values\n\nval_paths  = val_data.image_path.tolist()\nval_labels = val_data[config.TARGET_COLS].values\n\n\n#torch dataset\nbatch_size = 32\n\n# Create the datasets\n\ndataset_train = CustomDataset(train_paths, train_labels, transform=transform)\ntrain_dataloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n\n\ndataset_val = CustomDataset(val_paths, val_labels, transform=transform)\nval_dataloader = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)\n\n\n# Define your dataset size and other configuration parameters\ndataset_size = len(dataset_train)  # Assuming you have defined 'dataset' earlier\nbatch_size = 32  # Your batch size\ntotal_epochs = 50  # Total number of epochs\n\n# Calculate total train steps\ntotal_train_steps = dataset_size * batch_size * total_epochs\n\n# Define warmup steps as 10% of total train steps\nwarmup_steps = int(total_train_steps * 0.10)\n\n# Define decay steps as the remaining steps after warmup\ndecay_steps = total_train_steps - warmup_steps\n\nprint(f\"Total Train Steps: {total_train_steps}\")\nprint(f\"Warmup Steps: {warmup_steps}\")\nprint(f\"Decay Steps: {decay_steps}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T19:15:29.299574Z","iopub.execute_input":"2023-09-14T19:15:29.300146Z","iopub.status.idle":"2023-09-14T19:15:29.313924Z","shell.execute_reply.started":"2023-09-14T19:15:29.300109Z","shell.execute_reply":"2023-09-14T19:15:29.312868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for img, label in train_dataloader:\n  print(img.shape)\n  break","metadata":{"execution":{"iopub.status.busy":"2023-09-14T19:15:29.315734Z","iopub.execute_input":"2023-09-14T19:15:29.316456Z","iopub.status.idle":"2023-09-14T19:15:29.760736Z","shell.execute_reply.started":"2023-09-14T19:15:29.316417Z","shell.execute_reply":"2023-09-14T19:15:29.759801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## display some images","metadata":{}},{"cell_type":"code","source":"#a function to display images\ndef show_images(images, labels):\n    fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n    for idx, (image, label) in enumerate(zip(images, labels)):\n        image = image.permute(1, 2, 0)  # Convert from (C, H, W) to (H, W, C) for displaying\n        axes[idx].imshow(image)\n        label_str = \", \".join([str(val) for val in label])  # Convert label tensor to string\n        axes[idx].set_title(f\"Labels: {label_str}\")\n        axes[idx].axis(\"off\")\n    plt.show()\n\n# Load a few images for visualization\nnum_images_to_display = 5\nsample_indices = torch.randint(len(dataset_train), size=(num_images_to_display,))\nsample_images = [dataset_train[i][0] for i in sample_indices]\nsample_labels = [dataset_train[i][1] for i in sample_indices]\n\n# Convert label tensors to numpy arrays for display\nsample_labels_np = [label.numpy() for label in sample_labels]\n\n# Display the sample images\nshow_images(sample_images, sample_labels_np)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T19:15:29.762503Z","iopub.execute_input":"2023-09-14T19:15:29.762896Z","iopub.status.idle":"2023-09-14T19:15:30.424796Z","shell.execute_reply.started":"2023-09-14T19:15:29.762859Z","shell.execute_reply":"2023-09-14T19:15:30.423873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Simple CNN","metadata":{}},{"cell_type":"code","source":"class SimpleCNN(nn.Module):\n    def __init__(self, num_classes=11):\n        super(SimpleCNN, self).__init__()\n        \n        self.conv_layers = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.fc_layers = nn.Sequential(\n            nn.Linear(64 * 64 * 64, 128),\n            nn.ReLU(),\n            nn.Linear(128, num_classes)\n        )\n        \n    def forward(self, x):\n        x = self.conv_layers(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc_layers(x)\n        return x\n\n# Instantiate the model\nmodel = SimpleCNN(num_classes=11).to('cuda')","metadata":{"execution":{"iopub.status.busy":"2023-09-14T19:15:30.426174Z","iopub.execute_input":"2023-09-14T19:15:30.426724Z","iopub.status.idle":"2023-09-14T19:15:30.754351Z","shell.execute_reply.started":"2023-09-14T19:15:30.426688Z","shell.execute_reply":"2023-09-14T19:15:30.753313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## training the model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n\n# Instantiate the model\nmodel = SimpleCNN(num_classes=11).to('cuda')\n\n# Define loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()  # Use BCEWithLogitsLoss for binary classification\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5)\n\ntotal_epochs = 25  # Replace with the total number of epochs\n\n\ntrain_losses = []  # To store training losses\nval_losses = []    # To store validation losses\nval_accuracies = []  # To store validation accuracies\n\nfor epoch in range(total_epochs):\n    model.train()  # Set the model to training mode\n    for images, labels in train_dataloader:\n        optimizer.zero_grad()\n        \n        # Move data to GPU\n        images = images.to('cuda')\n        labels = labels.to('cuda')\n        \n        outputs = model(images)\n        \n        loss = criterion(outputs, labels)\n        \n        loss.backward()\n        optimizer.step()\n    \n    # Update learning rate using the scheduler\n    scheduler.step()\n    \n    # Validation loop\n    model.eval()  # Set the model to evaluation mode\n    val_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in val_dataloader:\n            images = images.to('cuda')\n            labels = labels.to('cuda')\n            \n            outputs = model(images)\n            val_loss += criterion(outputs, labels).item()\n            \n            predicted = (outputs > 0.5).int()  # Convert logits to binary predictions\n            total += labels.size(0) * labels.size(1)  # Total number of predictions\n            correct += (predicted == labels).sum().item()\n    \n    val_loss /= len(val_dataloader)\n    val_accuracy = 100.0 * correct / total\n    \n     # Append loss and accuracy values to lists\n    train_losses.append(loss.item())\n    val_losses.append(val_loss)\n    val_accuracies.append(val_accuracy)\n    print(f\"Epoch [{epoch+1}/{total_epochs}] - Loss: {loss:.4f} - Val Loss: {val_loss:.4f} - Val Acc: {val_accuracy:.2f}%\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:22:29.516872Z","iopub.execute_input":"2023-09-14T21:22:29.517465Z","iopub.status.idle":"2023-09-14T22:27:34.228557Z","shell.execute_reply.started":"2023-09-14T21:22:29.517427Z","shell.execute_reply":"2023-09-14T22:27:34.226325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training and validation progress\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label='Train')\nplt.plot(val_losses, label='Validation')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Training and Validation Loss')\n\nplt.subplot(1, 2, 2)\nplt.plot(val_accuracies, label='Validation')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')\nplt.legend()\nplt.title('Validation Accuracy')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T03:10:38.909085Z","iopub.execute_input":"2023-09-15T03:10:38.909450Z","iopub.status.idle":"2023-09-15T03:10:39.177640Z","shell.execute_reply.started":"2023-09-15T03:10:38.909420Z","shell.execute_reply":"2023-09-15T03:10:39.175763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Select a random image from the validation dataset\nrandom_index = np.random.randint(len(dataset_val))\nimage, label = dataset_val[random_index]\n\n# Move the image to the GPU if available\nimage = image.to('cuda')\n\n# Pass the image through the model\nwith torch.no_grad():\n    output = model(image.unsqueeze(0))  # Unsqueeze to add batch dimension\n\n# Convert the output logits to probabilities using sigmoid function\npredicted_probs = torch.sigmoid(output)[0]\n\n# Convert predicted probabilities to binary predictions\npredicted_labels = (predicted_probs > 0.5).int()\n\n\n# Display the image, actual labels, and predicted labels\nplt.imshow(image.permute(1, 2, 0).cpu())  # Move image to CPU and change channel order\n#plt.title(f\"Actual Labels: {label}\\nPredicted Labels: {predicted_labels}\")\nplt.title(f\"Actual Labels: {label}\\nPredicted Labels: {predicted_labels}\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T03:10:45.362832Z","iopub.execute_input":"2023-09-15T03:10:45.363679Z","iopub.status.idle":"2023-09-15T03:10:45.393284Z","shell.execute_reply.started":"2023-09-15T03:10:45.363634Z","shell.execute_reply":"2023-09-15T03:10:45.392025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}